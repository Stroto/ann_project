{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 128, 32, 32)       832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 64, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 64, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 32, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 32, 8, 128)        73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 32, 4, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 32, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 32, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 32, 2, 256)        295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 32, 1, 256)        0         \n",
      "_________________________________________________________________\n",
      "reshape_18 (Reshape)         (None, 32, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 32, 512)           1050624   \n",
      "_________________________________________________________________\n",
      "reshape_19 (Reshape)         (None, 32, 1, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 32, 1, 80)         368720    \n",
      "_________________________________________________________________\n",
      "reshape_20 (Reshape)         (None, 32, 80)            0         \n",
      "=================================================================\n",
      "Total params: 1,988,048\n",
      "Trainable params: 1,988,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Structure: 5 CNN\n",
    "# 2 5x5 kernel, 3 3x3 kernels\n",
    "# Non-linear RELU\n",
    "# MaxPool\n",
    "\n",
    "def backend_reshape(x):\n",
    "    return tf.keras.backend.reshape(x, (32,-1,80))\n",
    "\n",
    "\n",
    "def ctc_loss_fn(y_true, y_pred):\n",
    "    print(\"Y Prediction: \", y_pred.shape)\n",
    "    \"\"\"\n",
    "    y_pred = tf.transpose(y_pred, [1, 0, 2])\n",
    "\n",
    "    if len(y_true.shape) > 2:\n",
    "        y_true = tf.squeeze(y_true)\n",
    "\n",
    "    # y_pred.shape = (batch_size, string_length, alphabet_size_1_hot_encoded)\n",
    "    # output of every model is softmax\n",
    "    # so sum across alphabet_size_1_hot_encoded give 1\n",
    "    #               string_length give string length\n",
    "    input_length = tf.math.reduce_sum(y_pred, axis=-1, keepdims=False)\n",
    "    input_length = tf.math.reduce_sum(input_length, axis=-1, keepdims=True)\n",
    "    \n",
    "    \n",
    "    # y_true strings are padded with 0\n",
    "    # so sum of non-zero gives number of characters in this string\n",
    "    label_length = tf.math.count_nonzero(y_true, axis=-1, keepdims=True, dtype=\"int64\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "\n",
    "    # average loss across all entries in the batch\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    \"\"\"\n",
    "    return \n",
    "\n",
    "model = K.Sequential(\n",
    "    [\n",
    "        \n",
    "        layers.Conv2D(filters=32, kernel_size = 5, strides=1, padding=\"same\", input_shape = (128, 32,1), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=2, strides = (2,2)),\n",
    "        \n",
    "        layers.Conv2D(filters=64, kernel_size = 5, strides=1, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=2, strides = (2,2)),\n",
    "        \n",
    "        layers.Conv2D(filters=128, kernel_size = 3, strides=1, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(1,2), strides = (1,2)),\n",
    "        \n",
    "        layers.Conv2D(filters=128, kernel_size = 3, strides=1, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(1,2), strides = (1,2)),\n",
    "        \n",
    "        layers.Conv2D(filters=256, kernel_size = 3, strides=1, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(1,2), strides = (1,2)),\n",
    "        \n",
    "        layers.Reshape((32,256)),\n",
    "        \n",
    "        layers.Bidirectional(layers.LSTM(256, return_sequences=True)),\n",
    "        \n",
    "        layers.Reshape((32,1, 512)),\n",
    "        \n",
    "        layers.Conv2D(filters=80, kernel_size = 3, padding=\"same\", dilation_rate=1, activation=\"softmax\"),\n",
    "        layers.Reshape((32,80)),\n",
    "        \n",
    "        # layers.Lambda(backend_reshape)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=\"rmsprop\", loss=ctc_loss_fn, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some_file.py\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '/SimpleHTR')\n",
    "\n",
    "from SimpleHTR.src.DataLoader import DataLoader\n",
    "loader =  DataLoader(filePath='./SimpleHTR/data/', batchSize=50, imgSize=(128,32), maxTextLen=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tdef toSparse(texts, charList):\n",
    "\t\t\"put ground truth texts into sparse tensor for ctc_loss\"\n",
    "\t\tindices = []\n",
    "\t\tvalues = []\n",
    "\t\tshape = [len(texts), 0] # last entry must be max(labelList[i])\n",
    "\n",
    "\t\t# go over all texts\n",
    "\t\tfor (batchElement, text) in enumerate(texts):\n",
    "\t\t\t# convert to string of label (i.e. class-ids)\n",
    "\t\t\tlabelStr = [charList.index(c) for c in text]\n",
    "\t\t\t# sparse tensor must have size of max. label-string\n",
    "\t\t\tif len(labelStr) > shape[1]:\n",
    "\t\t\t\tshape[1] = len(labelStr)\n",
    "\t\t\t# put each label into sparse tensor\n",
    "\t\t\tfor (i, label) in enumerate(labelStr):\n",
    "\t\t\t\tindices.append([batchElement, i])\n",
    "\t\t\t\tvalues.append(label)\n",
    "\n",
    "\t\treturn (indices, values, shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimpleHTR.src.SamplePreprocessor import preprocess\n",
    "import cv2\n",
    "\n",
    "gtTexts = [loader.samples[i].gtText for i in range(len(loader.samples))]\n",
    "indices, values, dense_shape = toSparse(gtTexts[:int(len(gtTexts)*.95)], loader.charList)\n",
    "dense_shape[1] = 32\n",
    "y_train = tf.sparse.SparseTensor(indices, values, dense_shape)\n",
    "\n",
    "imgs_train = [preprocess(cv2.imread(loader.samples[i].filePath, cv2.IMREAD_GRAYSCALE), (128,32), False) for i in range(int(len(gtTexts)*.95))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'SparseTensor' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-03403147ecfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'SparseTensor' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(23750, 128, 32, 1), dtype=float64, numpy=\n",
       "array([[[[ 0.35059005],\n",
       "         [ 0.39148473],\n",
       "         [ 0.12566928],\n",
       "         ...,\n",
       "         [ 0.12566928],\n",
       "         [ 0.35059005],\n",
       "         [ 0.39148473]],\n",
       "\n",
       "        [[ 0.37103739],\n",
       "         [ 0.39148473],\n",
       "         [ 0.33014271],\n",
       "         ...,\n",
       "         [ 0.12566928],\n",
       "         [-0.05835679],\n",
       "         [-0.1605935 ]],\n",
       "\n",
       "        [[ 0.39148473],\n",
       "         [ 0.02343257],\n",
       "         [ 0.39148473],\n",
       "         ...,\n",
       "         [-0.05835679],\n",
       "         [ 0.12566928],\n",
       "         [ 0.35059005]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.39148473],\n",
       "         [ 0.39148473],\n",
       "         [ 0.39148473],\n",
       "         ...,\n",
       "         [ 0.39148473],\n",
       "         [ 0.39148473],\n",
       "         [ 0.39148473]],\n",
       "\n",
       "        [[ 0.39148473],\n",
       "         [ 0.39148473],\n",
       "         [ 0.39148473],\n",
       "         ...,\n",
       "         [ 0.39148473],\n",
       "         [ 0.39148473],\n",
       "         [ 0.39148473]],\n",
       "\n",
       "        [[ 0.39148473],\n",
       "         [ 0.39148473],\n",
       "         [ 0.39148473],\n",
       "         ...,\n",
       "         [ 0.39148473],\n",
       "         [ 0.39148473],\n",
       "         [ 0.39148473]]],\n",
       "\n",
       "\n",
       "       [[[-1.67229397],\n",
       "         [-1.69912152],\n",
       "         [-3.28194668],\n",
       "         ...,\n",
       "         [ 0.393427  ],\n",
       "         [ 0.393427  ],\n",
       "         [ 0.393427  ]],\n",
       "\n",
       "        [[-4.46235866],\n",
       "         [-4.86477184],\n",
       "         [-4.46235866],\n",
       "         ...,\n",
       "         [ 0.393427  ],\n",
       "         [ 0.393427  ],\n",
       "         [ 0.393427  ]],\n",
       "\n",
       "        [[ 0.15197909],\n",
       "         [ 0.15197909],\n",
       "         [ 0.25928927],\n",
       "         ...,\n",
       "         [ 0.393427  ],\n",
       "         [ 0.393427  ],\n",
       "         [ 0.393427  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.393427  ],\n",
       "         [ 0.393427  ],\n",
       "         [ 0.393427  ],\n",
       "         ...,\n",
       "         [ 0.393427  ],\n",
       "         [ 0.393427  ],\n",
       "         [ 0.393427  ]],\n",
       "\n",
       "        [[ 0.393427  ],\n",
       "         [ 0.393427  ],\n",
       "         [ 0.393427  ],\n",
       "         ...,\n",
       "         [ 0.393427  ],\n",
       "         [ 0.393427  ],\n",
       "         [ 0.393427  ]],\n",
       "\n",
       "        [[ 0.393427  ],\n",
       "         [ 0.393427  ],\n",
       "         [ 0.393427  ],\n",
       "         ...,\n",
       "         [ 0.393427  ],\n",
       "         [ 0.393427  ],\n",
       "         [ 0.393427  ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.33813169],\n",
       "         [ 0.24110811],\n",
       "         [ 0.07131683],\n",
       "         ...,\n",
       "         [-2.0874579 ],\n",
       "         [-0.51082467],\n",
       "         [ 0.07131683]],\n",
       "\n",
       "        [[ 0.33813169],\n",
       "         [ 0.33813169],\n",
       "         [ 0.33813169],\n",
       "         ...,\n",
       "         [-2.7181112 ],\n",
       "         [-0.36528929],\n",
       "         [ 0.07131683]],\n",
       "\n",
       "        [[ 0.33813169],\n",
       "         [ 0.33813169],\n",
       "         [ 0.33813169],\n",
       "         ...,\n",
       "         [-4.22197674],\n",
       "         [-4.14920906],\n",
       "         [-0.898919  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.33813169],\n",
       "         [ 0.33813169],\n",
       "         [ 0.33813169],\n",
       "         ...,\n",
       "         [ 0.33813169],\n",
       "         [ 0.33813169],\n",
       "         [ 0.33813169]],\n",
       "\n",
       "        [[ 0.33813169],\n",
       "         [ 0.33813169],\n",
       "         [ 0.33813169],\n",
       "         ...,\n",
       "         [ 0.33813169],\n",
       "         [ 0.33813169],\n",
       "         [ 0.33813169]],\n",
       "\n",
       "        [[ 0.33813169],\n",
       "         [ 0.33813169],\n",
       "         [ 0.33813169],\n",
       "         ...,\n",
       "         [ 0.33813169],\n",
       "         [ 0.33813169],\n",
       "         [ 0.33813169]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 0.27710369],\n",
       "         [ 0.27710369],\n",
       "         [ 0.21847275],\n",
       "         ...,\n",
       "         [ 0.10121089],\n",
       "         [ 0.12075453],\n",
       "         [ 0.27710369]],\n",
       "\n",
       "        [[ 0.29664733],\n",
       "         [ 0.25756004],\n",
       "         [ 0.15984182],\n",
       "         ...,\n",
       "         [ 0.10121089],\n",
       "         [ 0.19892911],\n",
       "         [ 0.25756004]],\n",
       "\n",
       "        [[ 0.27710369],\n",
       "         [ 0.25756004],\n",
       "         [ 0.15984182],\n",
       "         ...,\n",
       "         [-0.01605098],\n",
       "         [ 0.15984182],\n",
       "         [ 0.15984182]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.37482191],\n",
       "         [ 0.37482191],\n",
       "         [ 0.37482191],\n",
       "         ...,\n",
       "         [ 0.37482191],\n",
       "         [ 0.37482191],\n",
       "         [ 0.37482191]],\n",
       "\n",
       "        [[ 0.37482191],\n",
       "         [ 0.37482191],\n",
       "         [ 0.37482191],\n",
       "         ...,\n",
       "         [ 0.37482191],\n",
       "         [ 0.37482191],\n",
       "         [ 0.37482191]],\n",
       "\n",
       "        [[ 0.37482191],\n",
       "         [ 0.37482191],\n",
       "         [ 0.37482191],\n",
       "         ...,\n",
       "         [ 0.37482191],\n",
       "         [ 0.37482191],\n",
       "         [ 0.37482191]]],\n",
       "\n",
       "\n",
       "       [[[ 0.6593605 ],\n",
       "         [ 0.6593605 ],\n",
       "         [ 0.6593605 ],\n",
       "         ...,\n",
       "         [ 0.6593605 ],\n",
       "         [ 0.6593605 ],\n",
       "         [ 0.6593605 ]],\n",
       "\n",
       "        [[ 0.6593605 ],\n",
       "         [ 0.6593605 ],\n",
       "         [ 0.6593605 ],\n",
       "         ...,\n",
       "         [ 0.6593605 ],\n",
       "         [ 0.6593605 ],\n",
       "         [ 0.6593605 ]],\n",
       "\n",
       "        [[ 0.6593605 ],\n",
       "         [ 0.6593605 ],\n",
       "         [ 0.6593605 ],\n",
       "         ...,\n",
       "         [ 0.6593605 ],\n",
       "         [ 0.6593605 ],\n",
       "         [ 0.6593605 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.5476658 ],\n",
       "         [ 0.45458688],\n",
       "         [ 0.49181845],\n",
       "         ...,\n",
       "         [ 0.6593605 ],\n",
       "         [ 0.6593605 ],\n",
       "         [ 0.6593605 ]],\n",
       "\n",
       "        [[ 0.51043423],\n",
       "         [ 0.4359711 ],\n",
       "         [ 0.4359711 ],\n",
       "         ...,\n",
       "         [ 0.6593605 ],\n",
       "         [ 0.6593605 ],\n",
       "         [ 0.6593605 ]],\n",
       "\n",
       "        [[ 0.49181845],\n",
       "         [ 0.4359711 ],\n",
       "         [ 0.36150797],\n",
       "         ...,\n",
       "         [ 0.6593605 ],\n",
       "         [ 0.6593605 ],\n",
       "         [ 0.6593605 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.44647535],\n",
       "         [ 0.44647535],\n",
       "         [ 0.44647535],\n",
       "         ...,\n",
       "         [ 0.44647535],\n",
       "         [ 0.44647535],\n",
       "         [ 0.44647535]],\n",
       "\n",
       "        [[ 0.44647535],\n",
       "         [ 0.44647535],\n",
       "         [ 0.44647535],\n",
       "         ...,\n",
       "         [ 0.44647535],\n",
       "         [ 0.44647535],\n",
       "         [ 0.44647535]],\n",
       "\n",
       "        [[ 0.44647535],\n",
       "         [ 0.44647535],\n",
       "         [ 0.44647535],\n",
       "         ...,\n",
       "         [ 0.44647535],\n",
       "         [ 0.44647535],\n",
       "         [ 0.44647535]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.44647535],\n",
       "         [ 0.44647535],\n",
       "         [ 0.44647535],\n",
       "         ...,\n",
       "         [ 0.44647535],\n",
       "         [ 0.44647535],\n",
       "         [ 0.44647535]],\n",
       "\n",
       "        [[ 0.44647535],\n",
       "         [ 0.44647535],\n",
       "         [ 0.44647535],\n",
       "         ...,\n",
       "         [ 0.44647535],\n",
       "         [ 0.44647535],\n",
       "         [ 0.44647535]],\n",
       "\n",
       "        [[ 0.44647535],\n",
       "         [ 0.44647535],\n",
       "         [ 0.44647535],\n",
       "         ...,\n",
       "         [ 0.44647535],\n",
       "         [ 0.44647535],\n",
       "         [ 0.44647535]]]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_train = np.asarray(imgs_train)\n",
    "imgs_train = imgs_train.reshape((imgs_train.shape[0], imgs_train.shape[1], imgs_train.shape[2], 1))\n",
    "\n",
    "tf.convert_to_tensor(imgs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Prediction:  (None, 32, 80)\n",
      "WARNING:tensorflow:The dtype of the target tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\Joshua\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    C:\\Users\\Joshua\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Joshua\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Joshua\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Joshua\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:541 train_step  **\n        self.trainable_variables)\n    C:\\Users\\Joshua\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1804 _minimize\n        trainable_variables))\n    C:\\Users\\Joshua\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:521 _aggregate_gradients\n        filtered_grads_and_vars = _filter_grads(grads_and_vars)\n    C:\\Users\\Joshua\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:1219 _filter_grads\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['conv2d_36/kernel:0', 'conv2d_36/bias:0', 'conv2d_37/kernel:0', 'conv2d_37/bias:0', 'conv2d_38/kernel:0', 'conv2d_38/bias:0', 'conv2d_39/kernel:0', 'conv2d_39/bias:0', 'conv2d_40/kernel:0', 'conv2d_40/bias:0', 'bidirectional_6/forward_lstm_6/lstm_cell_19/kernel:0', 'bidirectional_6/forward_lstm_6/lstm_cell_19/recurrent_kernel:0', 'bidirectional_6/forward_lstm_6/lstm_cell_19/bias:0', 'bidirectional_6/backward_lstm_6/lstm_cell_20/kernel:0', 'bidirectional_6/backward_lstm_6/lstm_cell_20/recurrent_kernel:0', 'bidirectional_6/backward_lstm_6/lstm_cell_20/bias:0', 'conv2d_41/kernel:0', 'conv2d_41/bias:0'].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-1361cf25baf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    625\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 506\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2445\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2446\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2447\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2777\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2779\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2667\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2669\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\Joshua\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    C:\\Users\\Joshua\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Joshua\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Joshua\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Joshua\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:541 train_step  **\n        self.trainable_variables)\n    C:\\Users\\Joshua\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1804 _minimize\n        trainable_variables))\n    C:\\Users\\Joshua\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:521 _aggregate_gradients\n        filtered_grads_and_vars = _filter_grads(grads_and_vars)\n    C:\\Users\\Joshua\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:1219 _filter_grads\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['conv2d_36/kernel:0', 'conv2d_36/bias:0', 'conv2d_37/kernel:0', 'conv2d_37/bias:0', 'conv2d_38/kernel:0', 'conv2d_38/bias:0', 'conv2d_39/kernel:0', 'conv2d_39/bias:0', 'conv2d_40/kernel:0', 'conv2d_40/bias:0', 'bidirectional_6/forward_lstm_6/lstm_cell_19/kernel:0', 'bidirectional_6/forward_lstm_6/lstm_cell_19/recurrent_kernel:0', 'bidirectional_6/forward_lstm_6/lstm_cell_19/bias:0', 'bidirectional_6/backward_lstm_6/lstm_cell_20/kernel:0', 'bidirectional_6/backward_lstm_6/lstm_cell_20/recurrent_kernel:0', 'bidirectional_6/backward_lstm_6/lstm_cell_20/bias:0', 'conv2d_41/kernel:0', 'conv2d_41/bias:0'].\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=imgs_train,\n",
    "    y=y_train,\n",
    "    epochs=1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
